# Current sheet statistics

```{julia}
using Dates
using StatsBase, Statistics
using PSPAnisotropy
import Discontinuity as DC
using Discontinuity: var_mapping, compute_params!, filter_low_mva_quality
using Discontinuity: compute_Alfvenicity_params!, Alfven_velocity
using DimensionalData
using DataFrames, DataFramesMeta
using CairoMakie
using Beforerr: _theme_legend, easy_save
using AlgebraOfGraphics
import AlgebraOfGraphics as AoG
using Unitful
Unitful.preferunits(u"nA", u"km")

# https://github.com/MakieOrg/AlgebraOfGraphics.jl/issues/464
foreach([:log10, :log2, :log]) do f
    @eval import Base: $f
    @eval $f(x::Unitful.Quantity) = $f(ustrip(x))
end
set_Z_theme!()
formats = (:pdf,)
```

```{julia}
ð§ = :mva
ð’Ž = var_mapping(; ð§)

taus = Second.(2 .^ (1:6))
# taus = Second.(2 .^ (0:6))
df = workload(taus)
@chain df begin
    DC.compute_Alfvenicity_params!()
    DC.compute_params!()
    @transform!(:B_n_mva_norm = abs.(:B_n_mva ./ :B_mag))
    DC.classify!(:B_n_mva_norm)
end


# Count the number of events for each type
df_event_counts = @chain df begin
    groupby(:type)
    combine(nrow)
end
```

## Thickness and current density

Density distributions of (normalized) thickness and current density

```{julia}
subset_ð§(df, ð§) = ð§ == :mva ? filter_low_mva_quality(df) : df
fname = "properties_hist"

fs = map([:mva]) do ð§
    ð’Ž = var_mapping(; ð§)

    datalimits = x -> quantile(x, [0.01, 0.99])

    tdf = @chain df begin
        @subset(.!isnan.(:L_n_mva_norm); view=true)
        # @rsubset(((:id == "PSP") && :tau <= Second(2)) || (:id != "PSP" && :tau > Second(2))) # select current sheet events with tau <= 2s for PSP and tau > 2s for Earth
        subset_ð§(ð§)
        dropmissing(:L_n_mva_norm)
    end

    vars = [ð’Ž.l_log, ð’Ž.j_log, ð’Ž.l_norm_log, ð’Ž.j_norm_log]
    # , ð’Ž.bn
    labels = ["Thickness", "Current density", "Normalized thickness", "Normalized current density"]

    plt =
        data(tdf) *
        mapping(vars, layout=AoG.dims(1) => renamer(labels)) *
        # mapping(vars, row=AoG.dims(1) => renamer(labels), col=:type) *
        mapping(color=:id, linestyle=:enc) *
        AoG.density(; datalimits) * visual(Lines)
    draw(plt, axis=(; yscale=log10))
    easy_save("$fname-$ð§"; formats, force=true)
end
fs[1]
```

## Duration (temporal thickness)

Now we analyze what is the distribution of the duration of the current sheet, and how does it vary with the different tau we use.

Plot duration distributions for different missions and time periods.

```{julia}
let df = dropmissing(df, :duration)
    df.duration = ustrip.(df.duration .|> u"s")
    layer = AoG.density(; datalimits=x -> quantile(x, [0.02, 0.99])) * visual(Lines)
    # layer = AoG.histogram(; datalimits=x -> quantile(x, [0.02, 0.99]), bins = 0:0.3:30) * mapping(col=:id)
    plt = data(df) * mapping(:duration, linestyle=:enc, color=:id) * layer
    plt = plt + mapping(2 .^ (1:4)) * visual(VLines, color=:gray, linestyle=:dash)
    # plt *= (mapping(col=direct("col1")) + mapping(color=:tau, col=direct("col2")))
    # scales(Col=(; legend=false))
    draw(plt, axis=(; yscale=log10))
    easy_save("duration_dist"; formats, force=true)
end
```

Plot duration distributions faceted by different taus:

```{julia}
let df = dropmissing(df, :duration)
    df.duration = ustrip.(df.duration .|> u"s")
    layer = AoG.density(; datalimits=x -> quantile(x, [0.02, 0.99])) * visual(Lines)
    plt = data(df) * mapping(:duration, linestyle=:enc, color=:id) * layer
    plt *= mapping(layout=:tau)
    draw(plt, axis=(; yscale=log10), facet=(; linkxaxes=:none, linkyaxes=:none))
    easy_save("duration_dist_tau"; formats, force=true)
end
```

## Alfvenicity

```{julia}
ð’Ž = var_mapping(; ð§)

datalimits = x -> quantile(x, [0.01, 0.99])

tdf = @chain df begin
    @subset(.!isnan.(:V_l_ratio); view=true)
    subset_ð§(ð§)
    dropmissing(:V_l_ratio)
end

vars = [:Q_sonnerup => abs => "", :Î”V_ratio => identity => "", :V_l_ratio => identity => "", :V_l_ratio_max => identity => ""]
# ð’Ž.v_l_ratio, ð’Ž.bn
labels = ["Q_sonnerup", "Î” V ratio", "Î”V_l ratio", "Max Î”V_l ratio"]

plt =
    data(tdf) *
    mapping(vars, row=AoG.dims(1) => renamer(labels)) *
    #   mapping(vars, col=:tau, row=AoG.dims(1) => renamer(labels)) *
    mapping(color=:id, linestyle=:enc) *
    AoG.density(; datalimits) * visual(Lines)
draw(plt, axis=(; yscale=identity), facet=(; linkyaxes=:minimal))
# easy_save("Alfvenicities"; formats, force=true)
# draw(spec, scales(Layout=(; palette=wrapped(cols=2))); facet=(; linkyaxes=:none))
```

## 

Joint distributions of thickness and current density

```{julia}
for ð§ in [:mva]
    view = true
    ð’Ž = var_mapping(; ð§)

    tdf = @chain df begin
        # @subset(:enc .== enc)
        dropmissing()
        @transform(:L_n_mva = Float64.(ustrip.(:L_n_mva)), :J_m_max_mva = Float64.(ustrip.(:J_m_max_mva)))
        subset_ð§(ð§)
    end

    plt = alpha_layer(tdf, 0.618) * visual(Scatter; markersize=6, legend=(; alpha=0.6)) * mapping(color=:id, marker=:id)

    fig = Figure(size=(800, 300))
    axis = (; yscale=log10, xscale=log10)
    v_axis = (; yscale=log10, xscale=log10, limits=((2, 400), (2, 400)))

    ga = fig[1, 1]
    gb = fig[1, 2]
    gc = fig[2, 1]
    gd = fig[2, 2]

    spec1 = plt * mapping(ð’Ž.l, ð’Ž.j)
    spec2 = plt * mapping(ð’Ž.l_norm, ð’Ž.j_norm)
    spec3 = plt * mapping(:B_n_mva_norm, :Ï‰)
    spec4 = plt * mapping(:Î”V_ratio, :Î”V_cosÎ¸)

    grid1 = draw!(ga, spec1; axis)
    draw!(gb, spec2; axis)
    draw!(gc, spec3)
    draw!(gd, spec4; axis=(; limits=((0, 2), (-1, 1),)))

    # pretty_legend!(fig, grid1)
    # add_labels!([ga, gb, gc])
    # easy_save("$fname-$enc-$ð§"; formats, force=true)
    display(fig)
end
```


```{julia}
for ð§ in [:mva]
    view = true
    ð’Ž = var_mapping(; ð§)

    tdf = @chain df begin
        @subset(.!isnan.(:B_n_mva_norm) .& .!isnan.(:Ïƒ_c); view=true)
        dropmissing([:B_n_mva_norm, :duration, :Ïƒ_c])
        @transform!(:duration = Float64.(ustrip.(:duration .|> u"s")))
        subset_ð§(ð§)
    end

    plt = data(tdf) * mapping(row=:id, col=:enc)
    vis = visual(Scatter; markersize=6)
    fig = Figure(; size=(1200, 800))
    axis = (;)


    Î”V_cosÎ¸_group = :Î”V_cosÎ¸ => >(0)
    Î”V_cosÎ¸_map = mapping(group=Î”V_cosÎ¸_group, color=Î”V_cosÎ¸_group)

    B_n_spec = plt * mapping(:B_n_mva_norm, :Ï‰_in) * vis
    Î”V_spec = plt * mapping(:Î”V_ratio, :Î”V_cosÎ¸) * (vis + AoG.smooth() * Î”V_cosÎ¸_map)
    Ïƒc_Ïƒr_spec = plt * mapping(:Ïƒ_c, :Ïƒ_r) * (vis + AoG.smooth() * visual(color=:red))

    draw!(fig[1, 1], B_n_spec; axis)
    draw!(fig[1, 2], Î”V_spec; axis=(; limits=((0, 2), (-1, 1),)))
    draw!(fig[2, 1], Ïƒc_Ïƒr_spec)

    # pretty_legend!(fig, grid1)
    # add_labels!([ga, gb, gc])
    # easy_save("$fname-$enc-$ð§"; formats, force=true)
    display(fig)
end
```

Joint distributions of Q_sonnerup and other variables

```{julia}
CairoMakie.activate!()

view = true
ð’Ž = var_mapping(; ð§)

vars = [:B_n_mva_norm, :Q_sonnerup, :duration, :Ïƒ_c]

tdf = @chain df begin
    dropmissing(vars)
    @rsubset(all(!isnan, (:B_n_mva_norm, :Q_sonnerup, :Ïƒ_c)); view=true)
    @transform!(
        :duration = Float64.(ustrip.(:duration .|> u"s")),
        :B_n_mva_norm = Float64.(:B_n_mva_norm),
    )
end

A_He_df = @chain tdf begin
    dropmissing(:A_He)
    @transform!(:A_He = Float64.(only.(:A_He)))
    @rsubset(:A_He < 10)
end

Bn_df = subset_ð§(tdf, ð§)

fig = Figure(; size=(1200, 800))
axis = (;)

layout = mapping(row=:id, col=:enc)
plt = data(tdf) * layout
vis = visual(Scatter; markersize=6)

Q_group = mapping(group=:Q_sonnerup => >(0), color=:Q_sonnerup => >(0))
A_He_group = mapping(group=:A_He => >(0), color=:A_He => >(0))
line_vis = visual(linewidth=3)

Bn_Q_spec = data(Bn_df) * mapping(:B_n_mva_norm, :Q_sonnerup) * layout * (vis + AoG.linear() * Q_group * line_vis)
duration_Q_spec = plt * mapping(:duration, :Q_sonnerup) * (vis + AoG.smooth() * Q_group * line_vis)
Ïƒc_Q_spec = plt * mapping(:Ïƒ_c, :Q_sonnerup) * (vis + AoG.linear() * Q_group * line_vis)
Ïƒr_Q_spec = plt * mapping(:Ïƒ_r, :Q_sonnerup) * (vis + AoG.linear() * Q_group * line_vis)
A_He_Q_spec = data(A_He_df) * mapping(:A_He, :Q_sonnerup => abs) * layout * (vis + AoG.smooth() * A_He_group * line_vis)

draw!(fig[1, 1], Bn_Q_spec)
draw!(fig[1, 2], duration_Q_spec; axis=(; xscale=log10))
draw!(fig[2, 1], Ïƒc_Q_spec)
draw!(fig[2, 2], Ïƒr_Q_spec)
draw!(fig[3, 1], A_He_Q_spec)

# add_labels!([ga, gb, gc])
# easy_save("Q_sonnerup_joint_dist"; formats, force=true)
display(fig)
```


## Duration vs AlfvÃ©nicity Correlation

Let's analyze the relationship between duration and AlfvÃ©nicity to see if they are correlated.

```{julia}
using HypothesisTests
using NaNStatistics
using PairPlots

# Filter for clean data with both duration and AlfvÃ©nicity measures
vars = [:duration, :Q_sonnerup, :V_l_ratio, :B_n_mva_norm]

df_corr = @chain df begin
    filter_low_mva_quality()
    dropmissing(vars)
    @transform!(:duration = Float64.(ustrip.(:duration .|> u"s")))
    @rsubset(all(!isnan, (:Q_sonnerup, :V_l_ratio, :duration, :Ïƒ_c)))
end

# Overall correlation matrix
println("Overall correlation matrix:")
cor_vars = [:Q_sonnerup, :duration, :B_n_mva_norm, :Ïƒ_c, :Ïƒ_r, :L_n_mva_norm, :J_m_max_mva_norm]
overall_corr = nancor(Matrix(df_corr[!, cor_vars]))
display(overall_corr)
# heatmap(cor_vars, cor_vars, overall_corr)
# pairplot(df_corr[!, cor_vars])

# Group by different missions and compute correlations
println("\nCorrelation analysis by mission:")
mission_stats = @chain df_corr begin
    groupby(:id)
    @combine(
        :count = nrow,
        :corr_Q_duration = nancor(:Q_sonnerup, :duration),
        :corr_Bn_duration = nancor(:B_n_mva_norm, :duration),
        :corr_Q_Bn = nancor(:Q_sonnerup, :B_n_mva_norm),
        :mean_Q = nanmean(abs.(:Q_sonnerup)),
        :mean_duration = nanmean(:duration),
        :mean_Bn = nanmean(:B_n_mva_norm)
    )
end

display(mission_stats)

# # Statistical significance tests
# test_q = CorrelationTest(df_corr.duration_s, df_corr.Q_sonnerup)
# test_vl = CorrelationTest(df_corr.duration_s, collect(skipmissing(df_corr.V_l_ratio)))

# println("Statistical significance:")
# println("Duration vs Q_sonnerup: p-value = $(round(pvalue(test_q), digits=6))")
# println("Duration vs V_l_ratio: p-value = $(round(pvalue(test_vl), digits=6))")
```

Correlation Strength:
- Duration vs Q_sonnerup: r = -0.0253 (very weak negative correlation)
- Duration vs V_l_ratio: r = -0.0134 (very weak negative correlation)

Statistical Significance:
- Duration vs Q_sonnerup: p = 0.009 (statistically significant, p < 0.05)
- Duration vs V_l_ratio: p = 0.166 (not statistically significant, p > 0.05)

Interpretation:
1. There is a very weak negative correlation between duration and AlfvÃ©nicity - meaning longer events tend to be slightly less AlfvÃ©nic
2. The effect size is tiny (correlations ~-0.02 to -0.03) - practically negligible
3. Only Q_sonnerup shows statistical significance due to the large sample size (10,684 events)
4. The large sample size makes even tiny correlations statistically detectable, but they're not practically meaningful

Conclusion: While there's a statistically significant but extremely weak tendency for longer-duration current sheets to be slightly less AlfvÃ©nic, the correlation is so small it's essentially negligible in practical terms. Duration and AlfvÃ©nicity are largely independent of each other in this dataset.


## Unused Code

```{julia}
# Visualization: Scatter plot with trend line
f_corr = Figure(size=(1400, 600))

attrs = (alpha=0.6, markersize=6)

# Duration vs Q_sonnerup
ax1 = Axis(f_corr[1, 1],
    xscale=log10,
    xlabel="Duration (seconds)",
    ylabel="Q_sonnerup (AlfvÃ©nicity)",
    title="Duration vs AlfvÃ©nicity")

scatter!(ax1, df_corr.duration_s, abs.(df_corr.Q_sonnerup); color=:blue, attrs...)

# Add trend line (remove any remaining NaNs)
valid_idx = .!isnan.(df_corr.duration_s) .& .!isnan.(df_corr.Q_sonnerup)
if sum(valid_idx) > 0
    x_valid = df_corr.duration_s[valid_idx]
    y_valid = abs.(df_corr.Q_sonnerup[valid_idx])
    x_range = range(minimum(x_valid), maximum(x_valid), length=100)
    X = hcat(ones(length(x_valid)), x_valid)
    Î² = X \ y_valid
    trend_y = Î²[1] .+ Î²[2] .* x_range
    lines!(ax1, x_range, trend_y, color=:red, linewidth=2, linestyle=:dash)
end

# text!(ax1, 0.05, 0.95, "r = $(round(corr_duration_q, digits=4))", space=:relative, fontsize=12, color=:black)

# Duration vs V_l_ratio  
df_vl = dropmissing(df_corr, :V_l_ratio)
ax2 = Axis(f_corr[1, 2],
    xscale=log10,
    xlabel="Duration (seconds)",
    ylabel="V_l_ratio",
    title="Duration vs Velocity Ratio")

scatter!(ax2, df_vl.duration_s, df_vl.V_l_ratio,
    color=:green, alpha=0.6, markersize=6)

# Add trend line for V_l_ratio (remove any remaining NaNs)
valid_idx2 = .!isnan.(df_vl.duration_s) .& .!isnan.(df_vl.V_l_ratio)
if sum(valid_idx2) > 0
    x_valid2 = df_vl.duration_s[valid_idx2]
    y_valid2 = df_vl.V_l_ratio[valid_idx2]
    x_range2 = range(minimum(x_valid2), maximum(x_valid2), length=100)
    X2 = hcat(ones(length(x_valid2)), x_valid2)
    Î²2 = X2 \ y_valid2
    trend_y2 = Î²2[1] .+ Î²2[2] .* x_range2
    lines!(ax2, x_range2, trend_y2, color=:red, linewidth=2, linestyle=:dash)
end
ylims!(ax2, 0, 1)
# text!(ax2, 0.05, 0.95, "r = $(round(corr_duration_vl, digits=4))", space=:relative, fontsize=12, color=:black)

f_corr
```

```{julia}
using CategoricalArrays
using NaNStatistics
# Binned analysis
duration_bins = [0, 2, 5, 10, 20, 50, maximum(df_corr.duration_s)]
df_binned = @transform(df_corr,
    :duration_bin = cut(:duration_s, duration_bins, labels=["0-2s", "2-5s", "5-10s", "10-20s", "20-50s", ">50s"]))

binned_stats = @chain df_binned begin
    dropmissing([:Q_sonnerup, :V_l_ratio])
    groupby(:duration_bin)
    @combine(
        :count = length(:duration_s),
        :mean_duration = nanmean(:duration_s),
        :mean_Q_sonnerup = nanmean(abs.(:Q_sonnerup)),
        :std_Q_sonnerup = nanstd(abs.(:Q_sonnerup)),
        :mean_V_l_ratio = nanmean(:V_l_ratio),
        :std_V_l_ratio = nanstd(:V_l_ratio)
    )
end

println("Mean AlfvÃ©nicity by Duration Bins:")
select(binned_stats, :duration_bin, :count, :mean_Q_sonnerup, :mean_V_l_ratio)
```

```{julia}
# Add binned averages to the scatter plots
for (i, row) in enumerate(eachrow(binned_stats))
    if i < nrow(binned_stats)
        # Get bin boundaries
        bin_start = duration_bins[i]
        bin_end = duration_bins[i+1]
        bin_center = (bin_start + bin_end) / 2

        # Add mean points with error bars to Q_sonnerup plot
        scatter!(ax1, [bin_center], [row.mean_Q_sonnerup],
            color=:red, markersize=12, marker=:diamond)
        errorbars!(ax1, [bin_center], [row.mean_Q_sonnerup], [row.std_Q_sonnerup],
            color=:red, whiskerwidth=8, linewidth=2)

        # Add mean points with error bars to V_l_ratio plot  
        scatter!(ax2, [bin_center], [row.mean_V_l_ratio],
            color=:red, markersize=12, marker=:diamond)
        errorbars!(ax2, [bin_center], [row.mean_V_l_ratio], [row.std_V_l_ratio],
            color=:red, whiskerwidth=8, linewidth=2)
    else
        # Handle the last bin (>50s) - use a representative position
        bin_center = 60  # Approximate position for >50s bin

        scatter!(ax1, [bin_center], [row.mean_Q_sonnerup],
            color=:red, markersize=12, marker=:diamond)
        errorbars!(ax1, [bin_center], [row.mean_Q_sonnerup], [row.std_Q_sonnerup],
            color=:red, whiskerwidth=8, linewidth=2)

        scatter!(ax2, [bin_center], [row.mean_V_l_ratio],
            color=:red, markersize=12, marker=:diamond)
        errorbars!(ax2, [bin_center], [row.mean_V_l_ratio], [row.std_V_l_ratio],
            color=:red, whiskerwidth=8, linewidth=2)
    end
end

# Add legend explaining the red diamonds
Legend(f_corr[2, :], [MarkerElement(color=:red, marker=:diamond, markersize=12)],
    ["Binned Averages Â± Std"], orientation=:horizontal, tellwidth=false, tellheight=true)

f_corr
```
