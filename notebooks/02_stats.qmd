# Current sheet statistics

```{julia}
using Dates
using StatsBase, Statistics
using PSPAnisotropy
import Discontinuity as DC
using Discontinuity: var_mapping, compute_params!, filter_low_mva_quality
using Discontinuity: compute_Alfvenicity_params!, Alfven_velocity
using DimensionalData
using DataFrames, DataFramesMeta
using CairoMakie
using Beforerr: _theme_legend, easy_save
using AlgebraOfGraphics
import AlgebraOfGraphics as AoG
using Unitful
Unitful.preferunits(u"nA", u"km")

# https://github.com/MakieOrg/AlgebraOfGraphics.jl/issues/464
foreach([:log10, :log2, :log]) do f
    @eval import Base: $f
    @eval $f(x::Unitful.Quantity) = $f(ustrip(x))
end
set_Z_theme!()
formats = (:pdf,)
```

```{julia}
ğ§ = :mva
ğ’ = var_mapping(; ğ§)

taus = Second.(2 .^ (1:6))
# taus = Second.(2 .^ (0:6))
df = workload(taus)

_float64(x) = Float64(x)
_float64(::Missing) = missing

@chain df begin
    DC.compute_Alfvenicity_params!()
    DC.compute_params!()
    @transform!(
        :B_n_mva_norm = abs.(:B_n_mva ./ :B_mag),
        :duration = _float64.(ustrip.(:duration .|> u"s"))
    )
    DC.classify!(:B_n_mva_norm)
end


# Count the number of events for each type
df_event_counts = @chain df begin
    groupby(:type)
    combine(nrow)
end

subset_ğ§(df, ğ§) = ğ§ == :mva ? filter_low_mva_quality(df) : df
```


## Associations and independence test

```{julia}

println("\n" * "="^60)
println("ASSOCIATION ANALYSIS FOR ALFVÃ‰NICITY")
println("="^60)

# Define the variable pairs you want to analyze with transformations embedded
alfvenicity_pairs = [
    (:duration, :Q_sonnerup => abs, "Duration vs AlfvÃ©nicity (Q_sonnerup)"),
    (:duration, :V_l_ratio, "Duration vs Velocity Ratio (V_l_ratio)"),
    (:B_n_mva_norm, :Q_sonnerup => abs, "Magnetic Field Normal vs AlfvÃ©nicity"),
    (:Ïƒ_c, :Q_sonnerup, "Cross helicity vs AlfvÃ©nicity"),
    (:Ïƒ_r, :Q_sonnerup),
    (:Î², :Q_sonnerup => abs),
    (:A_He => x -> ismissing(x) ? missing : only(x), :Q_sonnerup => abs, "Helium Abundance vs AlfvÃ©nicity"),
    (:J_m_max_mva_norm, :Q_sonnerup => abs, "Current density vs AlfvÃ©nicity"),
    (:L_n_mva_norm, :Q_sonnerup => abs, "Thickness vs AlfvÃ©nicity"),
    (:A_He => x -> ismissing(x) ? missing : only(x), :J_m_max_mva_norm),
    (:A_He => x -> ismissing(x) ? missing : only(x), :L_n_mva_norm),
    (:Î², :J_m_max_mva_norm),
    (:Î², :L_n_mva_norm),
    (:Î², :A_He),
]

# Run overall analysis
println("OVERALL ASSOCIATION ANALYSIS")
println("="^50)
analyze_associations(df, alfvenicity_pairs)

# Grouped analysis
# println("GROUPED ASSOCIATION ANALYSIS (by $(group_by))")
println("="^50)
analyze_associations(df, alfvenicity_pairs; group_by=:id)
```


```md
Association Measure Interpretation:
Values range from 0 (no association) to 1 (perfect association):
- 0.0 - 0.1: Very weak association
- 0.1 - 0.3: Weak association  
- 0.3 - 0.5: Moderate association
- 0.5 - 0.7: Strong association
- 0.7 - 1.0: Very strong association

Association Methods Used:
1. Distance Correlation: Non-parametric measure detecting linear & nonlinear dependencies
2. Pearson Correlation: Standard linear correlation coefficient  
3. Spearman Correlation: Rank-based correlation (monotonic relationships)
4. Chatterjee Correlation: New robust measure for general dependencies
5. Mutual Information: Information-theoretic measure of shared information

Note: These are association strengths, not statistical significance tests.
For independence testing, use with caution - consider both effect size and sample size.
```

[](../association_results.txt)

```md

ğŸ” Step 1. General observations
	â€¢	Cross helicity vs AlfvÃ©nicity absolutely dominates:
	â€¢	Pearson = 0.84 overall (0.92 in PSP, 0.76 in Wind).
	â€¢	Chatterjee = 0.47â€“0.53.
	â€¢	MI = 0.58â€“0.97.
â†’ This is a very strong dependence by any metric, which is expected since AlfvÃ©nicity is conceptually related to cross helicity.
	â€¢	Magnetic field normal vs AlfvÃ©nicity shows weak-to-moderate positive linear correlation (~0.17â€“0.19), but Chatterjee and MI stay low. Suggests a weak linear trend, not a strong monotonic or nonlinear relationship.
	â€¢	Î£_r vs Q_sonnerup:
	â€¢	Small negative Pearson (~ -0.1).
	â€¢	But Chatterjee 0.09â€“0.15 and MI up to 0.24 in PSP â†’ weak, possibly nonlinear dependence.
	â€¢	This might indicate subtle structure missed by linear correlation.
	â€¢	Duration, velocity ratio, thickness, helium abundance, current density:
	â€¢	All show weak or negligible correlations (|Pearson| < 0.25, Chatterjee mostly < 0.06, MI close to 0).
	â€¢	Suggests near independence, with only minor dataset-specific effects (e.g., PSP helium abundance at -0.24).

â¸»

ğŸ” Step 2. Dataset comparison (PSP vs Wind)
	â€¢	Cross helicity vs AlfvÃ©nicity is strong in both spacecraft, but even stronger in PSP (r ~ 0.92 vs 0.76).
	â€¢	Magnetic field normal vs AlfvÃ©nicity is similar across PSP/Wind (r ~ 0.17â€“0.18).
	â€¢	Î£_r vs Q_sonnerup is stronger in PSP (MI ~0.24 vs 0.05 in Wind).
	â€¢	Helium abundance vs AlfvÃ©nicity:
	â€¢	PSP: moderate negative Pearson (-0.24).
	â€¢	Wind: near zero.
â†’ Suggests PSP-specific dependence (possibly tied to solar wind composition closer to the Sun).
	â€¢	The rest (duration, velocity ratio, thickness, current density) are consistently weak in both datasets.

â¸»

ğŸ” Step 3. Practical interpretation
	1.	Cross helicity is the defining feature of AlfvÃ©nicity.
The high correlations confirm that your AlfvÃ©nicity measure (Q_sonnerup) essentially tracks cross helicity. This is expected, but the strength of correlation (0.8â€“0.9) validates consistency across datasets.
	2.	Other plasma/structural properties are only weakly linked.
Magnetic field orientation (normal) shows a weak positive association, but not much more.
	3.	Î£_r (residual energy measure?) has a modest but interesting nonlinear association with AlfvÃ©nicity, especially in PSP. Could hint at a subtle dependence worth exploring with scatter plots or conditional analysis.
	4.	Helium abundance only matters in PSP.
The -0.24 Pearson suggests AlfvÃ©nicity tends to be lower in He-rich regions, but this trend does not appear in Wind. That could reflect heliocentric distance effects.

â¸»

âœ… Summary of main findings:
	â€¢	Strong dependence: Cross helicity â†” AlfvÃ©nicity (core relationship).
	â€¢	Weak but consistent: Magnetic field normal, Î£_r (especially in PSP).
	â€¢	Dataset-specific: Helium abundance (negative in PSP, absent in Wind).
	â€¢	Effectively independent: Duration, velocity ratio, thickness, current density.

â¸»
```


Would you like me to help you visualize these dependencies (scatter plots, density plots, MI heatmaps) to confirm the weak vs strong associations, or do you just need a written interpretation for now?

## Thickness and current density

Density distributions of (normalized) thickness and current density

```{julia}
fname = "properties_hist"

fs = map([:mva]) do ğ§
    ğ’ = var_mapping(; ğ§)

    datalimits = x -> quantile(x, [0.01, 0.99])

    tdf = @chain df begin
        @subset(.!isnan.(:L_n_mva_norm); view=true)
        # @rsubset(((:id == "PSP") && :tau <= Second(2)) || (:id != "PSP" && :tau > Second(2))) # select current sheet events with tau <= 2s for PSP and tau > 2s for Earth
        subset_ğ§(ğ§)
        dropmissing(:L_n_mva_norm)
    end

    vars = [ğ’.l_log, ğ’.j_log, ğ’.l_norm_log, ğ’.j_norm_log]
    # , ğ’.bn
    labels = ["Thickness", "Current density", "Normalized thickness", "Normalized current density"]

    plt =
        data(tdf) *
        mapping(vars, layout=AoG.dims(1) => renamer(labels)) *
        # mapping(vars, row=AoG.dims(1) => renamer(labels), col=:type) *
        mapping(color=:id, linestyle=:enc) *
        AoG.density(; datalimits) * visual(Lines)
    draw(plt, axis=(; yscale=log10))
    easy_save("$fname-$ğ§"; formats, force=true)
end
fs[1]
```

## Duration (temporal thickness)

Now we analyze what is the distribution of the duration of the current sheet, and how does it vary with the different tau we use.

Plot duration distributions for different missions and time periods.

```{julia}
let df = dropmissing(df, :duration)
    df.duration = ustrip.(df.duration .|> u"s")
    layer = AoG.density(; datalimits=x -> quantile(x, [0.02, 0.99])) * visual(Lines)
    # layer = AoG.histogram(; datalimits=x -> quantile(x, [0.02, 0.99]), bins = 0:0.3:30) * mapping(col=:id)
    plt = data(df) * mapping(:duration, linestyle=:enc, color=:id) * layer
    plt = plt + mapping(2 .^ (1:4)) * visual(VLines, color=:gray, linestyle=:dash)
    # plt *= (mapping(col=direct("col1")) + mapping(color=:tau, col=direct("col2")))
    # scales(Col=(; legend=false))
    draw(plt, axis=(; yscale=log10))
    easy_save("duration_dist"; formats, force=true)
end
```

Plot duration distributions faceted by different taus:

```{julia}
let df = dropmissing(df, :duration)
    df.duration = ustrip.(df.duration .|> u"s")
    layer = AoG.density(; datalimits=x -> quantile(x, [0.02, 0.99])) * visual(Lines)
    plt = data(df) * mapping(:duration, linestyle=:enc, color=:id) * layer
    plt *= mapping(layout=:tau)
    draw(plt, axis=(; yscale=log10), facet=(; linkxaxes=:none, linkyaxes=:none))
    easy_save("duration_dist_tau"; formats, force=true)
end
```

## Alfvenicity

```{julia}
ğ’ = var_mapping(; ğ§)

datalimits = x -> quantile(x, [0.01, 0.99])

tdf = @chain df begin
    @subset(.!isnan.(:V_l_ratio); view=true)
    subset_ğ§(ğ§)
    dropmissing(:V_l_ratio)
end

vars = [:Q_sonnerup => abs => "", :Î”V_ratio => identity => "", :V_l_ratio => identity => "", :V_l_ratio_max => identity => ""]
# ğ’.v_l_ratio, ğ’.bn
labels = ["Q_sonnerup", "Î” V ratio", "Î”V_l ratio", "Max Î”V_l ratio"]

plt =
    data(tdf) *
    mapping(vars, row=AoG.dims(1) => renamer(labels)) *
    #   mapping(vars, col=:tau, row=AoG.dims(1) => renamer(labels)) *
    mapping(color=:id, linestyle=:enc) *
    AoG.density(; datalimits) * visual(Lines)
draw(plt, axis=(; yscale=identity), facet=(; linkyaxes=:minimal))
# easy_save("Alfvenicities"; formats, force=true)
# draw(spec, scales(Layout=(; palette=wrapped(cols=2))); facet=(; linkyaxes=:none))
```

## Joint distributions

### Thickness and current density

```{julia}
for ğ§ in [:mva]
    view = true
    ğ’ = var_mapping(; ğ§)

    tdf = @chain df begin
        # @subset(:enc .== enc)
        dropmissing()
        @transform(:L_n_mva = Float64.(ustrip.(:L_n_mva)), :J_m_max_mva = Float64.(ustrip.(:J_m_max_mva)))
        subset_ğ§(ğ§)
    end

    plt = alpha_layer(tdf, 0.618) * visual(Scatter; markersize=6, legend=(; alpha=0.6)) * mapping(color=:id, marker=:id)

    fig = Figure(size=(800, 300))
    axis = (; yscale=log10, xscale=log10)
    v_axis = (; yscale=log10, xscale=log10, limits=((2, 400), (2, 400)))

    ga = fig[1, 1]
    gb = fig[1, 2]
    gc = fig[2, 1]
    gd = fig[2, 2]

    spec1 = plt * mapping(ğ’.l, ğ’.j)
    spec2 = plt * mapping(ğ’.l_norm, ğ’.j_norm)
    spec3 = plt * mapping(:B_n_mva_norm, :Ï‰)
    spec4 = plt * mapping(:Î”V_ratio, :Î”V_cosÎ¸)

    grid1 = draw!(ga, spec1; axis)
    draw!(gb, spec2; axis)
    draw!(gc, spec3)
    draw!(gd, spec4; axis=(; limits=((0, 2), (-1, 1),)))

    # pretty_legend!(fig, grid1)
    # add_labels!([ga, gb, gc])
    # easy_save("$fname-$enc-$ğ§"; formats, force=true)
    display(fig)
end
```


```{julia}
for ğ§ in [:mva]
    view = true
    ğ’ = var_mapping(; ğ§)

    tdf = @chain df begin
        @rsubset(all(!isnan, (:B_n_mva_norm, :Q_sonnerup, :Ïƒ_c, :Î”V_ratio, :Î”V_cosÎ¸)); view=true)
        dropmissing([:B_n_mva_norm, :duration, :Ïƒ_c])
        @transform!(:duration = Float64.(:duration))
        subset_ğ§(ğ§)
    end

    Î²_A_He_df = @chain df begin
        @rsubset(all(!isnan, (:Î², :A_He)); view=true)
        dropmissing([:Î², :A_He])
        @transform!(:log_Î² = log10.(:Î²))
        @rsubset(:A_He < 20, :log_Î² > -1.5)
    end


    layout = mapping(row=:id, col=:enc)

    plt = data(tdf) * layout
    vis = visual(Scatter; markersize=6)
    fig = Figure(; size=(1200, 800))
    axis = (;)


    Î”V_cosÎ¸_group = :Î”V_cosÎ¸ => >(0)
    Î”V_cosÎ¸_map = mapping(group=Î”V_cosÎ¸_group, color=Î”V_cosÎ¸_group)

    B_n_spec = plt * mapping(:B_n_mva_norm, :Ï‰_in) * vis
    Î”V_spec = plt * mapping(:Î”V_ratio, :Î”V_cosÎ¸) * (vis + AoG.linear() * Î”V_cosÎ¸_map)
    Ïƒc_Ïƒr_spec = plt * mapping(:Ïƒ_c, :Ïƒ_r) * (vis + AoG.smooth() * visual(color=:red))

    A_He_group = mapping(group=:A_He => >(1.5), color=:A_He => >(1.5))

    Î²_A_He_spec = data(Î²_A_He_df) * layout * mapping(:log_Î², :A_He) * (vis + AoG.smooth(; degree=1) * A_He_group)

    draw!(fig[1, 1], B_n_spec; axis)
    draw!(fig[1, 2], Î”V_spec; axis=(; limits=((0, 2), (-1, 1),)))
    draw!(fig[2, 1], Ïƒc_Ïƒr_spec)
    draw!(fig[2, 2], Î²_A_He_spec)

    # pretty_legend!(fig, grid1)
    # add_labels!([ga, gb, gc])
    # easy_save("$fname-$enc-$ğ§"; formats, force=true)
    display(fig)
end
```

### Q_sonnerup and other variables

```{julia}
view = true
ğ’ = var_mapping(; ğ§)

vars = [:B_n_mva_norm, :Q_sonnerup, :duration, :Ïƒ_c]

tdf = @chain df begin
    dropmissing(vars)
    @rsubset(all(!isnan, (:B_n_mva_norm, :Q_sonnerup, :Ïƒ_c)); view=true)
    @transform!(
        :duration = Float64.(:duration),
        :B_n_mva_norm = Float64.(:B_n_mva_norm),
    )
end

A_He_df = @chain tdf begin
    dropmissing(:A_He)
    @transform!(:A_He = Float64.(only.(:A_He)))
    @rsubset(:A_He < 10)
end

Î²_df = @chain df begin
    @rsubset(all(!isnan, [:Î², :Q_sonnerup]); view=true)
    dropmissing([:Î², :Q_sonnerup])
    @transform!(:log_Î² = log10.(:Î²))
end

Bn_df = subset_ğ§(tdf, ğ§)

fig = Figure(; size=(1200, 800))
axis = (;)

layout = mapping(row=:id, col=:enc)
plt = data(tdf) * layout
vis = visual(Scatter; markersize=5)

Q_group = mapping(group=:Q_sonnerup => >(0), color=:Q_sonnerup => >(0))
A_He_group = mapping(group=:A_He => >(0), color=:A_He => >(0))
line_vis = visual(linewidth=3)

Bn_Q_spec = data(Bn_df) * mapping(:B_n_mva_norm, :Q_sonnerup => abs) * layout * (vis + AoG.linear() * line_vis * mapping(color=:id))
duration_Q_spec = plt * mapping(:duration, :Q_sonnerup) * (vis + AoG.smooth() * Q_group * line_vis)
Ïƒc_Q_spec = plt * mapping(:Ïƒ_c, :Q_sonnerup) * (vis + AoG.linear() * Q_group * line_vis)
Ïƒr_Q_spec = plt * mapping(:Ïƒ_r, :Q_sonnerup) * (vis + AoG.linear() * Q_group * line_vis)
A_He_Q_spec = data(A_He_df) * mapping(:A_He, :Q_sonnerup => abs) * layout * (vis + AoG.smooth() * A_He_group * line_vis)
Î²_Q_spec = data(Î²_df) * mapping(:log_Î², :Q_sonnerup => abs) * layout * (vis + AoG.smooth(; degree=4) * line_vis * mapping(color=:id))

draw!(fig[1, 1], Bn_Q_spec)
draw!(fig[1, 2], duration_Q_spec; axis=(; xscale=log10))
draw!(fig[2, 1], Ïƒc_Q_spec)
draw!(fig[2, 2], Ïƒr_Q_spec)
draw!(fig[3, 1], A_He_Q_spec)
draw!(fig[3, 2], Î²_Q_spec)

# add_labels!([ga, gb, gc])
easy_save("Q_sonnerup_joint_dist"; formats, force=true)
display(fig)
```


## Duration vs AlfvÃ©nicity Correlation

Let's analyze the relationship between duration and AlfvÃ©nicity to see if they are correlated.

```{julia}
using HypothesisTests
using NaNStatistics
using PairPlots

# Filter for clean data with both duration and AlfvÃ©nicity measures
vars = [:duration, :Q_sonnerup, :V_l_ratio, :B_n_mva_norm]

df_corr = @chain df begin
    filter_low_mva_quality()
    dropmissing(vars)
    @transform!(:duration = Float64.(ustrip.(:duration .|> u"s")))
    @rsubset(all(!isnan, (:Q_sonnerup, :V_l_ratio, :duration, :Ïƒ_c)))
end

# Overall correlation matrix
println("Overall correlation matrix:")
cor_vars = [:Q_sonnerup, :duration, :B_n_mva_norm, :Ïƒ_c, :Ïƒ_r, :L_n_mva_norm, :J_m_max_mva_norm]
_cor_func = df -> nancor(Matrix(df[!, cor_vars]))
overall_corr = _cor_func(df_corr)
display(overall_corr)
# # Statistical significance tests
# test_q = CorrelationTest(df_corr.duration_s, df_corr.Q_sonnerup)
# test_vl = CorrelationTest(df_corr.duration_s, collect(skipmissing(df_corr.V_l_ratio)))

# println("Statistical significance:")
# println("Duration vs Q_sonnerup: p-value = $(round(pvalue(test_q), digits=6))")
# println("Duration vs V_l_ratio: p-value = $(round(pvalue(test_vl), digits=6))")
```

Correlation Strength:
- Duration vs Q_sonnerup: r = -0.0253 (very weak negative correlation)
- Duration vs V_l_ratio: r = -0.0134 (very weak negative correlation)

Statistical Significance:
- Duration vs Q_sonnerup: p = 0.009 (statistically significant, p < 0.05)
- Duration vs V_l_ratio: p = 0.166 (not statistically significant, p > 0.05)

Interpretation:
1. There is a very weak negative correlation between duration and AlfvÃ©nicity - meaning longer events tend to be slightly less AlfvÃ©nic
2. The effect size is tiny (correlations ~-0.02 to -0.03) - practically negligible
3. Only Q_sonnerup shows statistical significance due to the large sample size (10,684 events)
4. The large sample size makes even tiny correlations statistically detectable, but they're not practically meaningful

Conclusion: While there's a statistically significant but extremely weak tendency for longer-duration current sheets to be slightly less AlfvÃ©nic, the correlation is so small it's essentially negligible in practical terms. Duration and AlfvÃ©nicity are largely independent of each other in this dataset.


## Unused Code

```{julia}
# Visualization: Scatter plot with trend line
f_corr = Figure(size=(1400, 600))

attrs = (alpha=0.6, markersize=6)

# Duration vs Q_sonnerup
ax1 = Axis(f_corr[1, 1],
    xscale=log10,
    xlabel="Duration (seconds)",
    ylabel="Q_sonnerup (AlfvÃ©nicity)",
    title="Duration vs AlfvÃ©nicity")

scatter!(ax1, df_corr.duration_s, abs.(df_corr.Q_sonnerup); color=:blue, attrs...)

# Add trend line (remove any remaining NaNs)
valid_idx = .!isnan.(df_corr.duration_s) .& .!isnan.(df_corr.Q_sonnerup)
if sum(valid_idx) > 0
    x_valid = df_corr.duration_s[valid_idx]
    y_valid = abs.(df_corr.Q_sonnerup[valid_idx])
    x_range = range(minimum(x_valid), maximum(x_valid), length=100)
    X = hcat(ones(length(x_valid)), x_valid)
    Î² = X \ y_valid
    trend_y = Î²[1] .+ Î²[2] .* x_range
    lines!(ax1, x_range, trend_y, color=:red, linewidth=2, linestyle=:dash)
end

# text!(ax1, 0.05, 0.95, "r = $(round(corr_duration_q, digits=4))", space=:relative, fontsize=12, color=:black)

# Duration vs V_l_ratio  
df_vl = dropmissing(df_corr, :V_l_ratio)
ax2 = Axis(f_corr[1, 2],
    xscale=log10,
    xlabel="Duration (seconds)",
    ylabel="V_l_ratio",
    title="Duration vs Velocity Ratio")

scatter!(ax2, df_vl.duration_s, df_vl.V_l_ratio,
    color=:green, alpha=0.6, markersize=6)

# Add trend line for V_l_ratio (remove any remaining NaNs)
valid_idx2 = .!isnan.(df_vl.duration_s) .& .!isnan.(df_vl.V_l_ratio)
if sum(valid_idx2) > 0
    x_valid2 = df_vl.duration_s[valid_idx2]
    y_valid2 = df_vl.V_l_ratio[valid_idx2]
    x_range2 = range(minimum(x_valid2), maximum(x_valid2), length=100)
    X2 = hcat(ones(length(x_valid2)), x_valid2)
    Î²2 = X2 \ y_valid2
    trend_y2 = Î²2[1] .+ Î²2[2] .* x_range2
    lines!(ax2, x_range2, trend_y2, color=:red, linewidth=2, linestyle=:dash)
end
ylims!(ax2, 0, 1)
# text!(ax2, 0.05, 0.95, "r = $(round(corr_duration_vl, digits=4))", space=:relative, fontsize=12, color=:black)

f_corr
```

```{julia}
using CategoricalArrays
using NaNStatistics
# Binned analysis
duration_bins = [0, 2, 5, 10, 20, 50, maximum(df_corr.duration_s)]
df_binned = @transform(df_corr,
    :duration_bin = cut(:duration_s, duration_bins, labels=["0-2s", "2-5s", "5-10s", "10-20s", "20-50s", ">50s"]))

binned_stats = @chain df_binned begin
    dropmissing([:Q_sonnerup, :V_l_ratio])
    groupby(:duration_bin)
    @combine(
        :count = length(:duration_s),
        :mean_duration = nanmean(:duration_s),
        :mean_Q_sonnerup = nanmean(abs.(:Q_sonnerup)),
        :std_Q_sonnerup = nanstd(abs.(:Q_sonnerup)),
        :mean_V_l_ratio = nanmean(:V_l_ratio),
        :std_V_l_ratio = nanstd(:V_l_ratio)
    )
end

println("Mean AlfvÃ©nicity by Duration Bins:")
select(binned_stats, :duration_bin, :count, :mean_Q_sonnerup, :mean_V_l_ratio)
```

```{julia}
# Add binned averages to the scatter plots
for (i, row) in enumerate(eachrow(binned_stats))
    if i < nrow(binned_stats)
        # Get bin boundaries
        bin_start = duration_bins[i]
        bin_end = duration_bins[i+1]
        bin_center = (bin_start + bin_end) / 2

        # Add mean points with error bars to Q_sonnerup plot
        scatter!(ax1, [bin_center], [row.mean_Q_sonnerup],
            color=:red, markersize=12, marker=:diamond)
        errorbars!(ax1, [bin_center], [row.mean_Q_sonnerup], [row.std_Q_sonnerup],
            color=:red, whiskerwidth=8, linewidth=2)

        # Add mean points with error bars to V_l_ratio plot  
        scatter!(ax2, [bin_center], [row.mean_V_l_ratio],
            color=:red, markersize=12, marker=:diamond)
        errorbars!(ax2, [bin_center], [row.mean_V_l_ratio], [row.std_V_l_ratio],
            color=:red, whiskerwidth=8, linewidth=2)
    else
        # Handle the last bin (>50s) - use a representative position
        bin_center = 60  # Approximate position for >50s bin

        scatter!(ax1, [bin_center], [row.mean_Q_sonnerup],
            color=:red, markersize=12, marker=:diamond)
        errorbars!(ax1, [bin_center], [row.mean_Q_sonnerup], [row.std_Q_sonnerup],
            color=:red, whiskerwidth=8, linewidth=2)

        scatter!(ax2, [bin_center], [row.mean_V_l_ratio],
            color=:red, markersize=12, marker=:diamond)
        errorbars!(ax2, [bin_center], [row.mean_V_l_ratio], [row.std_V_l_ratio],
            color=:red, whiskerwidth=8, linewidth=2)
    end
end

# Add legend explaining the red diamonds
Legend(f_corr[2, :], [MarkerElement(color=:red, marker=:diamond, markersize=12)],
    ["Binned Averages Â± Std"], orientation=:horizontal, tellwidth=false, tellheight=true)

f_corr
```
